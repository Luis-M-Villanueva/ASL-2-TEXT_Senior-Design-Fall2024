from config_prep import DIR
import csv
import os
import numpy as np
import tensorflow as tf
import cv2
from tensorflow.keras.models import load_model  # type: ignore
from config_prep import mp_holistic, mp_drawing, mediapipe_detectionConversion, apply_landmarks, get_all_keypoints, TOTAL_NUM_FRAMES
import serial  # Add serial for reading the video data

print("Getting .keras models...")

cwd = os.getcwd()  # current working directory. duplicate of DIR from config_prep

model_files = [f for f in os.listdir(os.path.join(cwd, "models")) if f.endswith('.keras')]
for index, file in enumerate(model_files):
    print(f"{index}: {file}")

choice = int(input("See terminal. Pick model: "))
modelName = model_files[choice]
print(f"\nUsing model: {modelName}\n")

# find csv file with same name as model
csv_file = None
for file in os.listdir(os.path.join(DIR, 'models')):
    if file.startswith(modelName[:-6]) and file.endswith('.csv'):
        csv_file = os.path.join(os.path.join(cwd, 'models'), file)  # full path to csv file

if csv_file is None:
    print("No corresponding csv file.")
else:
    # read csv file
    glosses = []
    with open(csv_file, 'r') as file:
        reader = csv.reader(file)
        for row in reader:
            glosses.append(row[0])

    print(f"Glosses in this model via csv: {glosses}\n")

glosses = np.array(glosses)

model = load_model(os.path.join(os.path.join(cwd, 'models'), modelName))

# This code collects 30 frames/keypoints and makes a prediction, then moves on to the next one.
sequence = []
threshold = 0.4
frame_count = 0

# Initialize serial connection for video stream
ser = serial.Serial('/dev/ttyUSB0', 115200)  # Adjust the port and baud rate
img_data = bytearray()
header_found = False

with mp_holistic.Holistic(min_detection_confidence=0.4, min_tracking_confidence=0.4) as holistic:
    predicted_gloss = ""  # initialize to blank

    print("Waiting for video stream...")

    while True:
        try:
            byte = ser.read(1)  # Read one byte from serial
            if byte:
                if not header_found:
                    if byte == b'\xFF':
                        next_byte = ser.read(1)
                        if next_byte == b'\xD8':  # Start of JPEG
                            img_data.append(byte[0])
                            img_data.append(next_byte[0])
                            header_found = True
                else:
                    img_data.append(byte[0])
                    if byte == b'\xFF':
                        next_byte = ser.read(1)
                        img_data.append(next_byte[0])
                        if next_byte == b'\xD9':  # End of JPEG
                            frame_count += 1

                            # Convert the data into an image
                            np_img = np.frombuffer(img_data, dtype=np.uint8)
                            frame = cv2.imdecode(np_img, cv2.IMREAD_COLOR)

                            if frame is not None:
                                # Process the frame for gesture recognition
                                image, results = mediapipe_detectionConversion(frame, holistic)
                                apply_landmarks(image, results)

                                keypoints = get_all_keypoints(results)
                                sequence.append(keypoints)  # add to sequence
                                sequence = sequence[-TOTAL_NUM_FRAMES:]  # only keep last 30 frames

                                if len(sequence) == TOTAL_NUM_FRAMES:
                                    # Predict gesture
                                    pred_arry = model.predict(np.expand_dims(sequence, axis=0))[0]

                                    if pred_arry[np.argmax(pred_arry)] > threshold:
                                        predicted_gloss = glosses[np.argmax(pred_arry)]

                                    sequence.clear()

                                # Display the predicted gloss on the frame
                                cv2.putText(image, predicted_gloss, (10, image.shape[0] - 10),
                                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)

                                # Show the frame with prediction
                                cv2.imshow('Video Stream with Prediction', image)

                                if cv2.waitKey(1) & 0xFF == ord('q'):
                                    print("Stream stopped by user.")
                                    ser.close()
                                    cv2.destroyAllWindows()
                                    return

                            # Reset for the next frame
                            img_data = bytearray()
                            header_found = False

        except Exception as e:
            print(f"Error occurred: {e}")
            break

